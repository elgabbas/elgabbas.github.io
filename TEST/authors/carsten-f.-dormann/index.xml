<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Carsten F. Dormann | Ahmed El-Gabbas</title>
    <link>/authors/carsten-f.-dormann/</link>
      <atom:link href="/authors/carsten-f.-dormann/index.xml" rel="self" type="application/rss+xml" />
    <description>Carsten F. Dormann</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2018 - 2019 Ahmed El-Gabbas</copyright><lastBuildDate>Wed, 01 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>Carsten F. Dormann</title>
      <link>/authors/carsten-f.-dormann/</link>
    </image>
    
    <item>
      <title>Spatial conservation prioritisation in data-poor countries: a quantitative sensitivity analysis</title>
      <link>/publication/_elgabbas_etal_scp/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/publication/_elgabbas_etal_scp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Improved species-occurrence predictions in data-poor regions: using large-scale data and bias correction with down-weighted Poisson regression and Maxent</title>
      <link>/publication/2018_elgabbas_dormann_ecography/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>/publication/2018_elgabbas_dormann_ecography/</guid>
      <description>&lt;p&gt;&lt;p align=&#34;center&#34;&gt;
&lt;b&gt;Download PDF&lt;/b&gt;&lt;br&gt;&lt;a href=&#34;/Publications/El-Gabbas_Dormann_2018_Ecography.pdf&#34; onclick=&#34;return confirmSubmit()&#34; oncontextmenu=&#34;return false;&#34; target=&#34;_blank&#34; title=&#34;Download PDF of the paper&#34;&gt;&lt;img src=&#34;/img/PDF.png&#34; width=&#34;100&#34; height=&#34;100&#34;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;div style=&#34;display: none&#34;&gt;
El-Gabbas A. &amp;amp; Dormann C. F.: Improved species-occurrence predictions in data-poor regions: using large-scale data and bias correction with down-weighted Poisson regression and Maxent. Ecography DOI: 10.1111/ecog.03149.
Appendix 1: Supplementary figures and tables Table A1: The estimated optimum combination of Maxent’s feature classes (FC) and Regularization Multiplier (RM) for each species and bias model type. Combinations with highest mean testing-AUC on
5-folds spatial-block cross-validation were selected. All the analyses were performed using modified code from the ENMeval package in R (Muscarella et al., 2014). See main text for more information. Species Environment-only Accessibility Effort a
Feature classes (FC): L linear; Q quadratic; H hinge; P product; and T threshold. For more details see Elith et al. 2011. b RM is a global multiplier to all individual regularization values; for more details see the main text and Muscarella et al.
(2014). Table A2: Estimated best values to run the elastic-net models (DWPR approach) for different species and bias models. For details, see main text. Species Environment-only Accessibility Efforts LASSO RIDGE Fig. A1: Map of all non-marine
GBIF-records. There are clear signs of sampling bias inherited in the GBIF database, disallowing the direct use of these records to run SDMs, unless action is taken to correct for sampling bias. GBIF-records are biased mainly towards Western
Europe, with sparse locations across Africa, Asia, and Eastern Europe. Areas shown in white represent pixels without any records (the majority of North and central Africa, Arabia, and eastern Europe). Clearly errorneous records were excluded
before plotting this map.Fig. A2: Left: Map of all GBIF bat records (accessed date: April 2015) per a grid of 20 × 20 km2.Right: All records available of the study species, collected either from the literature (blue points) or GBIF (red points).
Both maps show large collection gaps. Fig. A3: Per-species study area: An example of how the ‘per-species’ study area was determined (here for Asellia tridens). The dashed red line indicates the species extent of occurrence (minimum convex
polygon); the solid red line shows the buffer used (1000 km), and the dashed green line indicates the study area used. Fig. A4: Variables selection: Pearson correlation coefficient between each pair of the final covariates; see Appendix 3 for more
information. Fig A5: Per-species number of backgrounds: Objectively determining the adequate number of background ‘quadrature’ points to be used in GLM and elastic-net models (see main text and Renner et al., 2015). DWPR-GLM models (for each
species, here: Asellia tridens) were repeated 25 times (each time, with a different random sample from the background) with progressively increase the number of background points (from 5000 to 500,000); and for each model, the log-likelihood value
is calculated and plotted. The number of backgrounds at which the likelihood converges (i.e. no much benefit of using a higher number of backgrounds) is, visually, selected to run the final models. Here, no much improvement in the log-likelihood
beyond 300,000 background points (out of 557,800 total available background points) and so we used it for this species. Fig. A6: Determining the best value to run the elastic-net model for Nycticeinops schlieffeni (effort model). Eleven values
ranging from zero (ridge) to one (lasso), with an increment of 0.1, were used to run 11 models on cross-validation. For each value of , glmnet ran many models on a range of -values (estimated from the data; x-axis) and measure the mean
cross-validation error (cvm) (here: Poisson deviance; y-axis). The value with the lowest cvm is used further while predicting (vertical dotted lines, with colours correspond to the value used). Here, an value of 0.6 is shown to have the lowest cvm
and so used further. For more details, see Table A2 and the main text. Fig. A7: Kendall’s correlation between (per-species and modelling algorithm) mean AUC evaluated on spatial-block cross-validation and independent evaluation in Egypt. Each
point represents the mean of 100 AUC values, with different symbols for each species. Colours represent different modelling algorithm used. ‘M’ indicates the overall mean for each modelling algorithm. Panel (a) shows the correlation for the
environment-only models (no bias correction). Panels (b-c) represent the accessibility model, without and with correcting for sampling bias, respectively. Panels (d-e) represent the effort model, without and with correcting for sampling bias,
respectively. Kendall’s correlation coefficients (and their p-values) are reported in each block. Grey solid line represents the equality line. AUC performed on cross-validation were, on average, higher than AUC in Egypt. However, there is
moderate correlation between bias-free evaluations on either scale. Fig. A8: Equivalent results to Fig. A7, for TSS evaluation. Fig A9: Boxplots of the raw cross-validation evaluation (100 values) without (modelling evaluation; a and c) and with
(bias-free evaluation; b and d) correction for sampling bias; either using AUC (a - b) or TSS (c - d); see Appendix 6 for more information. Horizontal panels show results for different modelling algorithm, while the vertical panels show different
bias models. Panels a &amp;amp; c show results for the environment-only model (without any bias manipulation) and bias-accounting models (accessibility and effort models) without correcting for sampling bias. However, panels b &amp;amp; d compare results for the
environment-only model and bias-accounting models (accessibility and effort models) after correcting for sampling bias (see main text; for effort models, plots show evaluations either conditioning the predictions on a value of zero or the maximum
relative sampling effort of training presences). Species are in ascending order according to their number of occupied pixels at cross-validation scale (with numbers represent the species; see Table 1 for full species names). Fig. A10: Similar to
Fig. A9, but showing results of independent evaluation in Egypt. Evaluation metrics are calculated in Egypt using mean predictions (of 5-folds cross-validation) in Egypt along with entirely independent species records from Egypt (not used to run
any of the models). Species are in ascending order according to their number of occupied pixels in Egypt (with numbers represent the species; see Table 1 for full species names). Fig. A11: Species mean TSS calculated either on cross-validation (a
- b) or in Egypt (c - d), either without (modelling evaluation; a &amp;amp; c) or with (bias-free evaluation; b &amp;amp; d) sampling bias correction (for details, see Appendix 6). Each species is represented by different symbols (similar to those shown in Fig.
A7; numbers represent species used, see Table 1). Red lines indicate the overall mean TSS at each modelling algorithm and bias models applied. Fig. A12: Kendall’s correlation of the per-species mean TSS between different pairs of modelling
algorithms (same as Fig. 2 in the main text, but for TSS). Each species is represented by different symbol (similar to those of Fig. A7) with different colours for different bias models applied (using predictions of environment-only model and
bias-free prediction of accessibility and effort model). ‘M’ indicates the overall mean evaluation. First row represents mean spatial-block cross-validation evaluation, while the second is for independent evaluations in Egypt. Fig. A13: Values of
bias variables at presences and available locations (backgrounds), at the per-species study area (A) or at local scale ‘Egypt’ (B). Rows correspond to different species, with numbers indicates the species (see Table 1), and columns represent bias
variables of the accessibility model (distances to roads, cities, and protected areas) and effort model (relative bats’ sampling intensity). For each species, values at presence locations are indicated with black, and values at pixels unoccupied
by the species are shown in grey. Most of the species are recorded from closer to roads and cities (and to some extent, the protected areas), and unexpectedly at low to moderate sampling efforts. Fig. A14: AUC scores calculated the default way
(using all available testing backgrounds – y-axis) versus using a fixed ratio between testing presences and backgrounds (test-data prevalence = 1:20 – x-axis). (A) shows the raw outputs of 5-folds cross-validation. (B) shows the per-species mean
AUC on cross-validation. Different colours represent the three bias models applied (environment-only, accessibility, and efforts). Fig. A15: The predicted distribution of Otonycteris hemprichii (mean of 5-folds cross-validation), using different
modelling algorithms (rows) and bias models (columns). Maps were scaled between zero and one, as different modelling algorithms do not have the same scale, with blue colour indicates higher predicted relative intensity. (A) shows cropped predicted
distribution of Otonycteris hemprichii (the same as Fig. 5) to Egypt. Grey points (in the top left panel) represents available records used for indepenent evaluation presences in Egypt. In Fig. 5 of the main text, extreme values (&amp;gt; 0.9995 quantile
of predicted values) were replaced with their next smaller value to improve map visualization, as GLM and elastic-net models sometimes yielded extreme values. Maps in (B) are equivalent to maps in Fig. 5, without any extreme values manipulation
(using the linear scale), demonstrating the difficulty of visualizing the predicted patterns in the existence of extreme values; see main text for more details. Fig. A16: The reported and predicted distribution of Rhinolophus mehelyi (Maxent). The
2nd to the 4th panels show predictions from environment-only model and bias-free prediction of accessibility and effort models, respectively. Arrows represent regions which gain higher predicted values after correcting for sampling bias (such as
central Turkey or the Algerian Atlas). Predictions at these areas are of higher uncertainty (lower congurrence) and field validation is probably required to confirm the species existence. The lighter the colour, the more suitable the location.
Appendix 3: Variables selection List of initial covariates investigated for correlation/multi-collinearity and transformation applied. Final list used to run the model is marked in grey. Variable Transfo- rmation VIF 10 | cor | 0.7 GVIF 3 Alt a
Altitude yes yes yes Bio1 Annual mean temperature ^2 Bio2 Mean diurnal range (mean of monthly (max temp - min temp)) yes yes yes Bio3 Isothermality (Bio2/Bio7) (* 100) Bio4 Temperature seasonality (standard deviation *100) yes yes yes Bio5 Maximum
temperature of warmest month Bio6 Minimum temperature of coldest month Bio7 Temperature annual range (Bio5-Bio6) Bio8 Mean temperature of wettest quarter ^2 yes yes yes Bio9 Mean temperature of driest quarter ^2 yes yes yes Bio10 Mean temperature
of warmest quarter ^2 Bio11 Mean temperature of coldest quarter yes yes Bio12 Annual precipitation sqrt Bio13 Precipitation of wettest month yes Bio14 Precipitation of driest month yes yes yes Bio15 Precipitation seasonality (coefficient of
variation) yes yes yes Bio16 Precipitation of wettest quarter sqrt Bio17 Precipitation of driest quarter Bio18 Precipitation of warmest quarter yes yes Bio19 Precipitation of coldest quarter log yes yes yes PET b Potential evapotranspiration AI b
Aridity index sqrt AET c Actual evapotranspiration sqrt SWB c Soil-water balance sqrt NDVI_Max d Maximum NDVI (Normalized Difference Vegetation Index) NDVI_Min d Minimum NDVI yes yes yes NDVI_Mean d Mean NDVI NDVI_Range d Range NDVI (maximum –
minimum) NDVI_SD d Standard deviation of NDVI yes yes yes EVI_Max d Maximum EVI (Enhanced Vegetation Index) EVI_Min d Minimum EVI yes EVI_Mean d Mean EVI yes EVI_Range d Range EVI (maximum - minimum) yes EVI_SD d Standard deviation of EVI a
WorldClim : WorldClim provides a global dataset for the elevation and 19 bio-climatic variables interpolated from global monthly temperature and precipitation recordings from weather stations (Hijmans et al. 2005). Tiles for the overall study area
were downloaded at 30 arc-seconds resolution (~1 km near the equator; using the raster R_package), then projected to Mollweide equal-area projection at 5 × 5 km2 resolution. The high resolution of 30 arc-seconds was preferred over the 2.5 arc
minutes (~5 km near the equator) in order not to lose much information while re-projecting. Instead of interpolation (assigning a value for the new pixel equals to the mean of the nearest three points at the original projection), a different
approach was employed. First, a template grid covering the study area at the equal-area projection (5 × 5 km2) was prepared. Then, pixels of the original variables (at 30 arc-seconds resolution) were converted into centroid points (at the original
projection: WGS-1984), then projected into Mollweide projection, then these points were rasterized using the mean value (or other relevant function for some variables; e.g. maximum for Bio5) of the points that spatially fall within each cell of
the template grid. The same approach was used to prepare all other covariates used in this study. b Global Potential Evapotranspiration (Global-PET) &amp;amp; Global Aridity (Zomer et al. 2007, 2008) : available at the global scale at a resolution of 1
km, and were prepared based on models that use data from WorldClim as inputs. Global Actual Evapotranspiration (Global-AET) &amp;amp; Global Soil-Water-Balance (Global-SWB) (Trabucco &amp;amp; Zomer 2010) : available at the global scale at a resolution of 1 km,
and are prepared based on WorldClim and Global-PET database as primary input. d NDVI (Normalized Difference Vegetation Index) &amp;amp; EVI (Enhanced Vegetation Index) (Didan, 2015) : map tiles for the whole study area were downloaded (and merged) for the
period from 18/2/2000 to 22/3/2015 each 16 days (MODIS product: MOD13A2 – resolution: 1 km) using the MODIS R package (Mattiuzzi, 2014). Summary maps (maximum, minimum, mean, range, and standard deviation) across the whole period (for NDVI &amp;amp; EVI)
were produced at the original MODIS scale/projection using a python code in ‘ArcGIS’ as this was memory intensive to perform in raster package of R. Each of the summary layers were then projected into the equal-area projection at 5 × 5 km2
resolution. Possible covariate transformations were investigated, trying to keep some degree of uniform distributions across the range of each covariate (following: Dormann 2011). For some covariates, no transformation was effective, and they were
kept untransformed. • Variable selection: Multicollinearity amongst the potential covariates )covering the total study area( was assessed, maintaining highest GVIF (Generalized Variance Inflation Factor) 3 (Zuur et al. 2009) [which is equivalent,
in our case, to maintaining a highest absolute correlation coefficient between each pair of covariates 0.6 and highest VIF (Variance Inflation Factor) 10]. This was also checked for each species’ study area. Aridity-related covariates
(actual/potential evapotranspiration, aridity-index, and soil-water-balance) were all excluded as they show high collinearity with other WorldClim covariates; unsurprisingly as they were derived from models that use WorldClim data as input. Out of
tensummary vegetation-related covariates, two NDVI covariates were used further: the cumulative minimum and the standard deviation NDVI. They reflect indices of minimum biomass and variability of vegetation-cover across the study area,
respectively. Appendix 4: Per-species spatial-block cross-validation For each species, a different spatial-block cross-validation structure was used to run SDMs. Pixels across the study area were aggregated into larger blocks (each of 20 × 20
cells = 100 × 100 km2), and blocks were distributed into cross-validation folds. Presences and backgrounds in each block were used together either as training or testing (Fithian et al. 2015). The blocks were not distributed into cross-validation
folds randomly, as this would have yielded highly unbalanced numbers of presence-locations across spatial folds. Instead, we balanced the number of presence locations at different folds by calculating their numbers at each block; the top 5 blocks
were then, sequentially, randomly assigned to five folds (to avoid that the first fold always has the highest number of presences). To avoid high variability in the environmental space between folds and minimise much extrapolation while predicting
to the left-out-fold, blocks without any species records were distributed into folds depending on a mean index of their similarity to the overall study area: using the Multivariate Environmental Similarity Surfaces ‘MESS’. MESS was proposed by
Elith et al. (2010) to identify areas of novel climates by comparing future (or past) climate to those used to run the models, as the interpretation of future projections at these locations should be considered with caution. We calculated the
MESS-score for each pixel (and a mean value for each block) quite differently from how it was proposed in the first place: we measured the environmental similarity of each pixel to all available pixels in the study area (using the ‘dismo’
package). The original application of MESS gives most dissimilar locations more negative values (Elith et al. 2010); however here we expect no negative values as there is no climates novelty. Blocks without any presence locations are sorted in
descending order (depending on their average MESS value), and then the highest five blocks were distributed randomly into different folds. This was repeated for all blocks until all blocks were distributed to different folds. An example of how
spatial-block cross-validation applied for Asellia tridens. Different colours represent how different blocks are distributed into cross-validation folds. Blue points represent the species known distribution from outside Egypt. For each per
species’ study area, a different blocking structure was prepared, to balance the number of presence locations and environmental variability at different cross-validation model runs. Appendix 5: Sampling-effort model Data for closely related
species (bats/non-marine mammals) were downloaded from GBIF (The Global Biodiversity Information Facility – April 2015) and used (along with available focal species records: Tables 1 &amp;amp; A1) to model the relative sampling intensity (surveying
effort) of bats/mammals. The prediction map of this model was used as bias covariate in the ‘Effort models’ (see main text, Fig. 1, bottom right). Records were assessed before usage (records with missing coordinates or with clear errors were
excluded: e.g. missed latitude or longitude / equal latitude and longitude / records in the sea or the ocean / potentially swapped latitude and longitude), resulting in a total of 435,458 bat records / 2,039,158 non-marine mammal records (maps
below). GBIF records (for both bats and mammals) show high bias towards the Western Europe compared to any other area in the study area, followed by scattered locations elsewhere (mostly close to the main cities, water bodies, populated areas, or
seemingly a result of a mammals atlas mapping activity in southwest Africa). The majority of Africa and eastern Europe to western Asia is extremely under-represented in GBIF, with huge gaps in North Africa and Arabia. Maps show the number of GBIF
records of non-marine mammals (left) and bats (right) per a grid of 20 × 20 km2 (accessed date: April 2015). Initial trials for modelling the sampling effort were done using DWPR-GLM (Down-Weighted Poisson Regression) and Maxent (both using
PPM-like approach; see main text); without much difference in the resulted prediction pattern (although Maxent model ‘using default feature classes and regularization multiplier’ shows, visually, an over-fitted spatial pattern). DWPR-GLM model was
chosen to run at 5×5 km2 equal-area projection: all the bats/mammals presence locations as the response (without duplicates removal) and using different covariate set than the environmental variables used to run the species SDMs (Merow et al.
2016) Terrain roughness (represented here as a per-pixel standard deviation of altitude): Altitude maps from WorldClim was downloaded at of 30 arc-seconds resolution [~1 km near the equator], then projected as points in Mollwide equal-area
projection. The points were then converted to a raster (rasterized), representing the standard deviation of the elevation values located at any target pixel at the resolution of 5 × 5 km2; Distance to main cities : the Euclidean distance between
the centroid of each pixel and the nearest human settlement; Distance to main roads : the Euclidean distance between the centroid of each pixel and the nearest road (Source: Global Roads Open Access Data Set ‘gROADS’); Population count : global
population count in 2000; Protection status : a binary variable indicating the protection status of each pixel [source: The world Database of Protected Areas:]. The overall pattern of the predicted sampling effort for both bats and mammals were
roughly similar (maps below), so the prediction from the bats sampling effort model was used further (as bias covariate in the effort model). It represents the overall relative abundance of bat species sightings per unit area (based only on
non-climatic covariates). The predicted sampling intensity of sightings (sampling effort) for all bats (left) and non-marine mammals (right) using the DWPR-GLM (Down-Weighted Poisson Regression) model. Appendix 6: Mixed effect model analysis of
evaluation Mixed Models formula: Evaluation metric ~ Modelling algorithms * Bias models + total number of training presences (training data) + number of pixels in the study area (total area) + (1 | species) Evaluation metric continuous variable
for either AUC or TSS either using mean cross-validation evaluation (AUCcv/TSScv) or independent evaluation in Egypt (using mean prediction of 5-folds cross-validation to Egypt and independent testing data from Egypt) Modelling algorithms:
categorical variable indicating the modelling algorithm used (elastic net / GLM / Maxent) Bias models: 1. Modelling evaluation: evaluation of environment-only model (base line; no bias manipulation) is compared with those of bias-accounting models
(accessibility and effort), without correction for sampling bias [without fixing bias variables at any values]. 2. Bias correction evaluation: evaluation of environment-only model (base line; no bias manipulation) is compared with those of bias
accounting models (accessibility and effort), after correction for sampling bias [accessibility bias variables are set to zero, while the effort bias variable is set to either zero or the maximum estimated effort of the target species’ presence
records; see below]. Species: random factor; categorical variable for the species. Modelling Evaluation – Without Bias correction Variance explained (sum of squares) AUC TSS Mean cross-validation Egypt evaluation Mean cross-validation Egypt
evaluation Bias models Model techniques Bias models * Model techniques Total number of training presences Study area Parameter estimates (Mixed models summary) Bias correction evaluation – using bias-free predictionsAfter correcting for sampling
bias, initial trials show that using either value for fixing the effort bias covariate produce very similar evaluations (however, Maxent models show quite lower AUCs using the maximum effort value of training presences than for fixing at zero;
Fig. 3), so we limited further analyses to effortMax.When predicting with fixed values for the bias-covariates, modelling algorithms were most important for explaining variability of cross-validations, followed by sampling-bias models and then
their interaction (for evaluation in Egypt highest variability was explained by the sampling-bias models, followed by the modelling algorithm, and then their interaction). Again, the number of training presences and study area were much less
important (and the sign of their effects resembles those of modelling evaluation). The accessibility model had lower AUC compared to the two other sampling-bias models in all comparisons (Fig. 3). On cross-validation, bias-accounting models had
lower AUC-values compared to the environment-only model (very little difference between environment-only and effort model for GLM; Fig. 3a). For evaluations in Egypt, environment-only and effort model were hardly different (effort model had lower
AUC for Maxent ; Fig. 3b).Variance explained (sum of squares) AUC TSS Mean cross-validation Egypt evaluation Mean cross-validation Egypt evaluation Bias models Model techniques Total number of training presences Study area Parameter estimates
(Mixed models summary) AUC TSS Mean cross-validation Egypt evaluation Mean cross-validation Egypt evaluation(Intercept) [env-only/ elastic net] Estimated differences in the least square means AUC TSS Mean cross-validation Egypt evaluation Mean
cross-validation Egypt evaluation Modelling techniques Supplementary references Didan K (2015): MOD13A2 MODIS/Terra Vegetation Indices 16-Day L3 Global 1km SIN Grid V006. NASA EOSDIS Land Processes DAAC. Dormann CF (2011): Modelling Species’
Distributions. In Fred J, Hauke R, Broder B (Eds.): Modelling Complex Ecological Dynamics. Berlin, Heidelberg: Springer Berlin Heidelberg, pp. 179–196. Elith J, Kearney M, Phillips S (2010): The art of modelling range-shifting species. Methods in
Ecology and Evolution 1: 330–342. Fithian, W., Elith, J., Hastie, T., Keith, D.A. &amp;amp; O&amp;rsquo;Hara, R.B. (2015). Bias correction in species distribution models: pooling survey and collection data for multiple species. Methods in Ecology and Evolution, 6,
424–438. Friedman J, Hastie T, Tibshirani R (2010): Regularization Paths for Generalized Linear Models via Coordinate Descent. Journal of Statistical Software, 33(1), 1-22. URL: &lt;a href=&#34;http://www.jstatsoft.org/v33/i01/&#34; target=&#34;_blank&#34;&gt;http://www.jstatsoft.org/v33/i01/&lt;/a&gt;. Hijmans RJ, Cameron SE, Parra JL,
Jones PG, Jarvis A (2005): Very high resolution interpolated climate surfaces for global land areas. In Int. J. Climatol. 25 (15), pp. 1965–1978. Merow C, Allen JM, Aiello-Lammens M &amp;amp; Silander JA (2016): Improving niche and range estimates with
Maxent and point process models by integrating spatially explicit information. Global Ecology and Biogeography, 25, 1022–1036. Mattiuzzi M (2014): MODIS: MODIS acquisition and processing. R package version 0.10-17/r484.
(&lt;a href=&#34;https://R-Forge.R-project.org/projects/modis/&#34; target=&#34;_blank&#34;&gt;https://R-Forge.R-project.org/projects/modis/&lt;/a&gt;) Renner IW, Elith J, Baddeley A, Fithian W, Hastie T, Phillips SJ., et al. (2015): Point process models for presence-only analysis. Methods in Ecology and Evolution 6: 366–379. Trabucco A, Zomer RJ
(2010): Global Soil Water Balance Geospatial Database. CGIAR Consortium for Spatial Information. Published online, available from the CGIAR-CSI GeoPortal at: &lt;a href=&#34;http://www.cgiar-csi.org&#34; target=&#34;_blank&#34;&gt;http://www.cgiar-csi.org&lt;/a&gt;. Zomer RJ, Bossio DA, Trabucco A, Yuanjie L, Gupta DC, Singh VP
(2007): Trees and Water: Smallholder Agroforestry on Irrigated Lands in Northern India. Colombo, Sri Lanka: International Water Management Institute. pp 45. (IWMI Research Report 122). Zomer RJ, Trabucco A, Bossio DA, van Straaten O, Verchot LV
(2008): Climate Change Mitigation: A Spatial Analysis of Global Land Suitability for Clean Development Mechanism Afforestation and Reforestation. Agric. Ecosystems and Envir. 126: 67-80. Zuur AF, Ieno EN, Walker NJ, Saveliev AA, Smith GM (2009):
Mixed Effects Models and Extensions in Ecology with R. New York, NY: Springer New York.
&lt;/div&gt;&lt;/p&gt;

&lt;div style=&#34;display: none&#34;&gt;
El-Gabbas A. &amp; Dormann C. F.: Improved species-occurrence predictions in data-poor regions: using large-scale data and bias correction with down-weighted Poisson regression and Maxent. Ecography DOI: 10.1111/ecog.03149. Ahmed El-Gabbas &amp; Carsten
F. Dormann Department of Biometry and Environmental System Analysis, University of Freiburg, D-79106 Freiburg, Germany bat, Maxent, point-process model, presence-only data, species distribution modelling, sampling bias Running-title: Bias
correction for sparse presence-only data Abstract Species distribution modelling (SDM) has become an essential method in ecology and conservation. In the absence of survey data, the majority of SDMs are calibrated with opportunistic presence-only
data, incurring substantial sampling bias. We address the challenge of correcting for sampling bias in the data-sparse situations. We modelled the relative intensity of bat records in their entire range using three modelling algorithms under the
point-process modelling framework (GLMs with subset selection, GLMs fitted with an elastic net penalty, and Maxent). To correct for sampling bias, we applied model-based bias correction by incorporating spatial information on site accessibility or
sampling efforts. We evaluated the effect of bias correction on the models’ predictive performance (AUC and TSS), calculated on spatial-block cross-validation and a holdout data set. When evaluated with independent, but also sampling-biased test
data, correction for sampling bias led to improved predictions. The predictive performance of the three modelling algorithms was very similar. Elastic-net models have intermediate performance, with slight advantage for GLMs on cross-validation and
Maxent on hold-out evaluation. Model-based bias correction is very useful in data-sparse situations, where detailed data are not available to apply other bias correction methods. However, bias correction success depends on how well the selected
bias variables describe the sources of bias. In this study, accessibility covariates described bias in our data better than effort covariates, and their use led to larger changes in predictive performance. Objectively evaluating bias correction
requires bias-free presence-absence test data, and without them the real improvement for describing a species’ environmental niche cannot be assessed. Introduction Species distribution data often come in the form of presence-only, with information
on where species have been recorded, but no reliable information on where they have not, or where people have looked (Pearce and Boyce 2006). Museums, herbaria, personal collections, published literature, and citizen records are valuable sources
for presence-only data (Pearce and Boyce 2006, Newbold 2010), especially in developing countries where there is a lack of systematic nation-wide surveys. Some initiatives make such species sightings freely available: GBIF (the Global Biodiversity
Information Facility – see: http://www.gbif.org) collates global biodiversity data from different sources. One fundamental problem is that data are often incidental with no information on the sampling efforts and survey method used (Pearce and
Boyce 2006). They are biased taxonomically (towards larger, easy to detect, or more charismatic species groups; Newbold 2010), environmentally (less collection effort in areas with harsh environments), temporally (more in summer than winter), and
spatially (near populated places, roads, research institutes and protected areas; Phillips et al. 2009, Newbold 2010, Stolar and Nielsen 2015). For example, GBIF-data show huge differences in data contribution among countries (Supplementary
material Appendix 1, Fig. A1; on average, more from well-financed than from species-rich countries). Spatial bias is a particular concern for statistical analysis when it leads to environmental bias (Phillips et al. 2009), e.g. when large parts of
the environmental space remain unsampled (Merow et al. 2014). Species distribution models (SDMs) relate species occurrences to the environment to estimate habitat preference, and predict potential distribution and responses to climate change
(Phillips and Dudík 2008, Elith et al. 2011). Statistical analyses of presence-only data describe the environment at record locations relative to the background environment, making them more susceptible to sampling bias than presence-absence data
from dedicated surveys (Phillips et al. 2009, Fithian et al. 2015). However, such targeted survey-data are rare (Pearce and Boyce 2006), especially in developing countries, explaining why the majority of SDM applications uses presence-only data.
Presence-only data may produce sound models if they are efficiently corrected for sampling bias (Elith et al. 2011). Point-process models (PPM) have recently emerged as the most appropriate technique for presence-only data (Renner et al. 2015).
PPMs do not use background points as pseudo-absences (as in the naïve logistic regression; Fithian and Hastie 2013), but rather as quadrature points for estimating the spatial integral of the likelihood function, and hence require careful tuning
of its number (for details see, e.g., Warton and Aarts 2013). The response variable of PPMs is the density of species records per unit area (also called ‘intensity’), which should be proportional to the probability of occurrence (which can not be
estimated empirically using presence-only data without additional information; see: Fithian and Hastie 2013, Renner et al. 2015, Phillips et al. 2017). It is mathematically equivalent to methods already commonly used in ecology, e.g. Maxent and
some implementations of the generalised linear modelling framework, but differently efficient (Renner and Warton 2013, for details, see: Renner et al. 2015). Sampling bias has been addressed by ‘spatial filtering’ of presence locations (keeping
only a limited number of records within a certain distance) to dilute the effect of uneven sampling effort across the study area (e.g. Anderson and Raza 2010, Boria et al. 2014). Alternatively, others effectively use location of records from
related species as background points to have background points with the same bias as the species records (Elith and Leathwick 2007, &#39;target-group background&#39;: Phillips et al. 2009, see also: Ponder et al. 2001, and &#39;weighted target group&#39;
presented in Anderson 2003). Neither approach is applicable when there are only few data (a typical case in developing countries). For example, to apply the target-group background approach to model the distribution of a bat species in North
Africa, all GBIF bat species records (Supplementary material Appendix 1, Fig. A2) are clearly not enough to serve as representative background points in this large study area. Similar to the target-group background, if the pattern of sampling bias
is known a priori, it can be used as prior weight for sampling the background proportionally to the sampling effort (e.g. &#39;bias file&#39; in Maxent; Phillips and Dudík 2008, Warren et al. 2014), so that both presences and background samples have the
same bias (see also: Stolar and Nielsen 2015). As a third strategy, sampling bias can be addressed also by modelling the distribution of the focal species as a function of two additive covariate sets: the environmental covariates and other
covariate(s) describing potential sources of sampling bias, hereafter ‘bias covariates’ (model-based bias correction; Warton et al. 2013). For unbiased predictions, the bias covariates are set to a common level of bias, say 0, at all locations;
however, sometimes it is difficult to settle on a meaningful adjustment level (Warton et al. 2013). The aim of this paper is to address the problem of sampling bias in data-sparse situations and how to correct for it in presence-only SDMs. We
apply model-based bias correction, comparing two different sets of bias covariates to model the distribution of Egyptian bat species in areas of their known global distributions. Bias-models for each of three modelling techniques within the PPM
framework are calibrated with information on either accessibility or sampling effort and compared to an ‘environment-only model’. To maintain a reasonable degree of independence between training and testing datasets, we evaluated the models using
a) entirely independent presence-only data (not used to fit any of the models); and b) spatial-block cross-validation.   Materials and methods Species and study area We are interested in understanding the environmental preferences of Egyptian bats
as an example representing the sampling-bias issue in data-sparse situations. We collected records for the entire range of each species (Supplementary material Appendix 1, Fig. A2, latitude: −35° to +56° and longitude: −20° to +80°) from the
literature and GBIF (see Supplementary material Appendix 2 for list of literature sources). Although GBIF provides a valuable source of data, such opportunistically compiled data bases inevitably contain misidentified or incorrectly georeferenced
records (Gaiji et al. 2013), and thus require careful revision before use. Relevant records from the GBIF database were assessed (October 2014) and merged with the available literature records. Bat records from Egypt were mostly taken from the
expert-revised BioMAP (Biodiversity Monitoring and Assessment Project) database (Basuony et al. 2010). Only species with enough presence locations that are located in at least 5 larger spatial blocks were included in this study (allowing model
evaluation on spatial-block cross-validation; see below). This was fulfilled by 21 species, each occupying &gt; 20 unique cells at resolution of 5×5 km2 (Table 1). The geographical range of records was assessed (based on the literature and IUCN), and
spatial outliers were excluded. The coverage of all available records shows obvious signs of spatial bias towards Western Europe and only sparse sampling in Africa and Western Asia (Supplementary material Appendix 1, Fig. A2). Presence locations
were purposefully split into training and testing data, using only records from outside Egypt’s boundaries for training, thereby keeping the Egyptian presence data as entirely independent evaluation data. For sampling of background points,
however, Egypt was not excluded from the study area, and hence background points can be sampled from Egypt as well (see Fig. 1 for a flowchart of the methods applied). The determination of the study area is critical, especially for presence-only
models (Pearce and Boyce 2006). We decided against a single fixed large study area that covers presence locations of all 21 species to keep only areas of potential accessibility to the bats (Barve et al. 2011) and avoid inflating the
discrimination ability of the model (e.g. higher AUC; Barve et al. 2011). Instead, for each species, the study area was determined based on the geographical extent of the records: a rectangular bounding box containing a 1000 km buffer around the
species extent of occurrence (see Supplementary material Appendix 1, Fig. A3 for an example). We used a buffer of 1000 km, as we found it suitable for the study species ‘bats’, which have, on average, high dispersal ability and large home range.
Potential covariates (and species presences) were projected into Mollweide equal-area projection and rasterised to a resolution of 5 × 5 km2. We assessed potential environmental variables for multi-collinearity, and assembled a final list of
covariates with a maximum Generalized Variance Inflation Factor value less than 3 (for details see Supplementary material Appendix 3 &amp; Supplementary material Appendix 1, Fig. A4). Block cross-validation Cross-validation is commonly used for
evaluating model performance when no independent data are available. Random splitting does not guarantee spatial independence due to spatial autocorrelation (both training and testing data will be spatially adjacent), and so may overestimate model
performance (Bahn and McGill 2013, Radosavljevic and Anderson 2014). To maintain independence between folds and improve transferability of models, a spatial form of cross-validation was used by splitting the study area into coarse checkerboard
blocks, and then distribute blocks randomly into folds (Fithian et al. 2015). We performed 5-fold spatial-block cross-validation (hereafter: cross-validation). The larger the block size, the higher is the need for more data to be able to run
models on spatial-block cross-validation. We used blocks of 100 × 100 km2 (20 × 20 cells), which is not very strong, as we find this more appropriate for the available data. Presence and background locations within each block were used together
for model training or testing: for the three modelling algorithms, potential background locations of the left-out cross-validation fold were not used (masked) during model calibration and were used exclusively for evaluation (similar to &#39;masked
geographically structured approach&#39; of Radosavljevic and Anderson 2014, see also Fig. 7 in Fithian et al. 2015). For each species, we used a different blocking structure, balancing the number of available presences between folds and avoiding
extrapolation in environmental space (for more details see Supplementary material Appendix 4). Sampling-bias models We compared models without bias correction (environment-only model, our reference) with two methods of addressing bias. Firstly, we
considered human accessibility as the main source of sampling bias and ran SDMs with additional bias covariates describing distances to nearest cities, roads and protected areas (the ‘accessibility model’). For bias-free predictions, we set all
distances to zero; thus, a bias-free prediction can be interpreted as the relative intensity of the target species records if all locations across the study area had perfect accessibility (Warton et al. 2013). Second, assuming relative effort is
the main source of sampling bias, we incorporated a single bias covariate describing the relative intensity of sightings of all bat species (the ‘effort model’). This sampling-effort bias covariate was actually the prediction from a (different)
all-bats-model, which predicted the number of all records as a function of non-environmental variables (terrain roughness, distance to cities, distance to main roads, human population density, protected area – details in Supplementary material
Appendix 5 and Fig. 1 bottom-right). For bias-adjusted predictions, the sampling-effort covariate needed to be set to a common level, for which there is no obvious choice. We therefore adjusted it to either of two values of sampling effort: the
maximum fitted value at the target species&#39; training presence locations, and at zero. In the first case, the bias-adjusted prediction can be interpreted as the relative intensity of species reporting if all the study area receives the sampling
effort of the best presence location of the target species. In the second case, the bias-adjusted prediction is independent of effort, and the effort covariate is used only to correct the coefficients of the environmental variables. Although the
latter value seems simpler, the predicted values lack intuitive interpretation. As the results were very similar, we here only use the maximum fitted value at training presences. Modelling algorithms For each sampling bias model (environment-only,
accessibility and effort), we employed three modelling algorithms under the PPM framework with cross-validation and adjustment for model complexity: GLM, elastic net, and Maxent. Both GLM and elastic net model the number of records as a Poisson
regression, with elastic net including a mixture of lasso and ridge regularisation (shrinkage; L1- and L2-regularisation, respectively; Friedman et al. 2010). Maxent (v3.3.3k; Phillips and Dudík 2008) is a machine-learning algorithm for
presence-only data, effectively and mathematically akin to a Poisson GLM, but with different functional forms for the predictors; it also applies an ad-hoc form of lasso regularisation (Renner and Warton 2013). We used GLM and elastic net to
implement a “down-weighted Poisson regression” (DWPR, following Renner et al. 2015). This approach uses weights to make the number of presences a negligible proportion of all data and scales the data to the actual area. As a consequence, DWPR
estimates model parameters including the intercept. A small weight (10-6) was assigned to presence locations, while background points were given a higher weight equal to the area of the study region divided by the number of background points used.
To estimate the appropriate number of background points (for GLM and elastic net), 25 repeated series of DWPR-GLMs were run, each one progressively increasing the number of randomly sampled background points. We used the number of background
points at which the log-likelihood asymptoted (Supplementary material Appendix 1, Fig. A5; Renner et al. 2015). For both GLM and elastic-net models, 1) we included linear, quadratic and 1st-order interactions between variables; 2) no interactions
were allowed between the environmental and bias covariates (Warton et al. 2013); 3) we standardised all covariates to a mean of zero and standard deviation of one. For GLMs, a random sample of background points (number estimated from the
asymptoted log-likelihood curve) was used to run an initial model. The initial model was then simplified using AIC-informed backward stepwise selection and the remaining variables were used to cross-validate the final models. Running elastic net
(R package glmnet; Friedman et al. 2010) requires tuning of two parameters, α (describes the balance of ridge and lasso) and λ (degree of regularisation; for more details see: Hastie et al. 2009). For each species and bias manipulation, we
estimated the best combination of α and λ by 5-fold cross-validation of 11 models (α ranging from zero to one with an increment of 0.1). For each model, the optimal λ value was determined by fitting a series of cross-validated models to a range of
λ values (‘regularisation path’; by default 100 values estimated from the data) and the λ value that showed the minimum mean cross-validated error was used for predictions. Similarly, the α value with the lowest error (Poisson deviance) was
selected (Supplementary material Appendix 1, Fig. A6). To report the performance of the elastic net (and for comparisons with the results of other techniques), the selected values of α and λ were used to run the cross-validation models manually.
Due to the computational limitation of explicitly using a user-defined λ during model training (stated by glmnet help page), models were fitted without providing a λ-value, allowing the fit of many models over the regularisation path. For
prediction we used the optimal λ-value estimated from cross-validation. The best-estimated values of α are shown in Supplementary material Appendix 1, Table A2. Lasso (α = 1) rather than ridge was chosen for almost half of the species in
environment-only and accessibility models. For the effort model, only three species had ridge models (α = 0) and all others had α-values 1. Maxent default settings were adapted according to advice in the literature (Merow et al. 2013,
Radosavljevic and Anderson 2014). Maxent, by default, uses combinations of feature classes (transformations of covariates: linear “L”, quadratic “Q”, hinge “H”, threshold “T”, and product “P”) depending on the number of presence locations
available, allowing for complex species-environment relationships (Phillips and Dudík 2008). We adapted functions from the ENMeval package (Muscarella et al. 2014) to run Maxent models on cross-validation at different complexity levels and feature
class combinations (48 models = 8 regularisation multiplier values ranging from 0.5 to 4 with increment of 0.5 × 6 feature class combinations [L / LQ / H / LQH / LQHP / LQHPT]). The default number of background points used by Maxent (10,000) is
insufficient to represent the environmental variability in large study areas as used here (Renner and Warton 2013), and hence all potential grids were considered as background points. We used clamping while predicting to the left-out fold, meaning
that if any value of a covariate is beyond its training range, these values will be replaced by the closest value during training (Anderson and Raza 2010). For each species and bias manipulation, the combination of regularisation multiplier and
feature class that shows the highest mean testing-AUC (on cross-validation) were selected for predictions. The optimum combinations of Maxent’s feature classes and regularisation multiplier are shown in Supplementary material Appendix 1, Table A1.
The selected feature classes deviated from Maxent’s default: 10 species always had simple features (L/LQ) for all bias manipulations, with the effort model showing more complex features in some cases. Moreover, the best-estimated regularisation
multiplier also deviated from the default value of one, with many species having values &gt;1, indicating little overfitting. Model evaluation We evaluated the models using threshold-independent (the area under the ROC curve, AUC) and
threshold-dependent (True Skill Statistic, TSS) metrics. We tried to avoid some of the metrics&#39; known caveats through 1) the use of species-specific study areas; 2) block cross-validation minimising environmental extrapolation; and 3) using the
same blocking structure to run different modelling techniques and bias manipulations of the same species. In presence-only SDMs, presences comprise only a tiny fraction of the background. During evaluation, the use of too many background points
with equal weights for commission and omission error can distort the evaluation (Lobo et al. 2008). To be able to compare AUCs (computed using the dismo R package) among models for the same species, we set the numbers of test presences and random
test background (test data prevalence) to a ratio of 1:20, and repeated this 100 times to average stochastic effects. TSS was calculated using the threshold that maximises the sum of sensitivity and specificity (Liu et al. 2013), again using a
constant ratio of presences and background. AUC and TSS were calculated for each combination of species, algorithm and bias manipulation. We summarised the overall effect of different bias manipulations in two ways, using linear mixed-effect
models (R-package lme4; Bates et al. 2015). Firstly, to evaluate the effect of incorporating bias covariates into the model, we compared evaluation of the environment-only models (without any bias correction) to those of bias-accounted models
(accessibility and effort) without conditioning on a particular value of the bias covariate during prediction (modelling evaluation). Second, to explore the effect of bias correction on model evaluation, we performed similar comparisons, with
bias-free predictions of the bias-accounted models instead (bias correction evaluation; for details see Supplementary material Appendix 6). We expect models incorporating the impact of bias to outperform (signified by a higher AUC or TSS) those
that do not. The problem is that we do not have bias-free data, and therefore our test data exhibit the same bias as the data used to create the model. Under these circumstances, models allowing for bias may be worse than those that do not. In
either case, the difference between bias-corrected and control models is a measure of the impact of bias. In the mixed models, we used model evaluation as response variable, species as random effect, and model type, bias correction (and their
interactions), total number of training presences, and total number of pixels at per-species study area (range size) as fixed effects (for more details, see Supplementary material Appendix 6). Results Validation by block cross-validation vs. by
Egypt hold-out The overall mean AUC is 0.88 ± 0.08 on cross-validation (0.75 ± 0.13 in Egypt’s evaluation; Figs. 2-3). Because results for AUC and TSS were similar, we present only results for AUC (see Supplementary material Appendix 1, Fig. A11
and supplement for TSS). Model evaluations in Egypt were, on average, poorer than on cross-validation. However, both types of evaluation (using ‘bias-corrected’ predictions) show positive correlation (Kendall’s tau; n=21 – Supplementary material
Appendix 1, Fig. A7), with highest consistency for the accessibility model. As expected, species with fewer occupied cells tend to have higher evaluation variability (uncertainty), and hence provide less robust analyses (Supplementary material
Appendix 1, Figs. A9-10). Effect of bias corrections: mixed-effect model analysis across species and model types Sampling-bias model explained most of the variation in model validation, followed by the modelling algorithm, and their interaction
(Fig. 2 and Supplementary material Appendix 6.1). The total number of training presence (positive effect) and the range size (negative effect) were much less important. On average, the accessibility model performed much better than
environment-only and effort models (Figs. 2 and Supplementary material Appendix 6.1). For mean cross-validations, effort models also had relatively higher AUCs than the environment-only model (the difference is much smaller for elastic net and
GLM; Figs. 2a). However, for validation in Egypt, effort models were similar to the environment-only model (Figs. 2b , see also Supplementary material Appendix 6.1). We can also evaluate the performance of the sampling-bias models when their bias
covariates are set to a fixed value, i.e. when predicting to bias-free data. However, since we have no reference survey data to compare them to, these predictions reveal the impact of bias-correction on the model, rather than assess the model’s
performance. These evaluations are presented in Fig. 3 and Supplementary material Appendix 6.2. Effect of model type The predictive performance of the three modelling algorithms showed fair to moderately high correlation coefficient (most r &gt; 0.6,
all significant; Fig. 4). For mean cross-validation evaluations, GLM performed best, followed by elastic net and Maxent. The order is reversed for independent validations in Egypt: Maxent has highest AUC-values, followed by elastic net, then GLM
(Figs. 2-4, and Supplementary material Appendix 6).  Discussion Sampling bias, if not corrected for effectively, can substantially affect the predicted intensity and model evaluation of SDMs. Our results suggest that accessibility bias covariates
describe the bias in our focal species’ training data well, compared to sampling efforts, and their use led to higher validation scores. Evaluated on data that are themselves spatially biased, we find that removing sampling bias did not improve
the predictive performance on cross-validation or in Egypt (Fig. 3), highlighting the limitation of evaluating bias correction without independent bias-free presence-absence data. Collectively, the three modelling algorithms performed similarly
well in cross-validation, though predicting to new sites (Egypt) gave Maxent a slight advantage (Figs. 2b and 3b). Sampling-bias correction using presence-only data Few approaches exist to correct for sampling bias, some not applicable when data
are sparse. Spatial filtering (i.e. aggregation to single records within some larger buffer: e.g. Anderson and Raza 2010, Boria et al. 2014) might be wasteful when only few presences exist. Removal of clumped data will reduce training sample size
and may remove some of the environmental conditions occupied by the species (depending on the heterogeneity of the landscape, selected distance, and pixel size). Target-group background selection strictly assumes that related species were
collected with the same method and equipment (Phillips et al. 2009), bias is similar across species (Warton et al. 2013), and species have the same chance of being recorded in all locations (Yackulic et al. 2013). Moreover, it replaces the
observer bias with a (spatial) species-richness bias and can be understood as modelling the likelihood of encountering the target species rather than a non-target species (Warton et al. 2013, Warren et al. 2014). Also, it does not distinguish
between areas unsuitable for any of the species and areas of low accessibility (no records, but potentially suitable: Warren et al. 2014, Fithian et al. 2015). The target-group background cannot be used when data on the related species are
similarly limited, as this increases the risk of extrapolating in environmental space (Mateo et al. 2010, Merow et al. 2013). Bias layers attempt to describe with which biases presence locations were recorded (Phillips et al. 2009, Warton et al.
2013). Our external sampling-effort model (Fig. 1 bottom right) is such an attempt to derive a bias layer (e.g. Elith et al. 2010). The bias layer is currently only implemented in Maxent, and we are not aware of any study that applied a similar
approach using other modeling algorithms. To maintain consistency of the analyses across different modelling algorithms we did not consider using a bias layer here. Both bias layer and target-group are used to sample background with the same bias
as presence locations, which is a sensitive tuning step that strongly influences model evaluation (Chefaoui and Lobo 2008). We think that model-based bias correction, as applied here, is more plausible in data deficient situations and if applied
efficiently, it frees us from artificially manipulating presences or background points, and rather focus on sampling bias correction. The effectiveness of bias correction depends on whether bias covariates are actually able to describe the bias in
the available data. Our use of either accessibility or sampling effort bias covariates did not lead to notably different conclusions (see Fig. 5). Using sampling-effort bias covariate led to, on average, little to moderate evaluation changes
(Figs. 2-3). It is in fact a model-based version of the target-group background approach, without strict selection of the background data points. The assumption that closely related species have similar bias may not hold. Surprisingly, most of the
available presences of our focal species were located in areas of low to moderate estimated efforts (Supplementary material Appendix 1, Fig. A13), but still strongly biased towards roads and cities (and, to less extent, protected areas;
Supplementary material Appendix 1, Fig. A13). Ideally, evaluating bias correction requires independent ‘bias-free’ presence-absence testing data (Phillips et al. 2009). Such data are typically not available, especially in developing countries, and
removing bias from test data is very difficult (Dudík et al. 2005, Smith 2013). On average, validation of bias-corrected predictions using well-structured, independent presence-absence data from rigorous surveys led to improved predictions (Elith
and Leathwick 2007, Phillips et al. 2009, Mateo et al. 2010, Syfert et al. 2013, Warton et al. 2013, Boria et al. 2014). However, this improvement is not happening in all situations and depends on the modelling conditions, species prevalence,
validity of assumptions, and how effective bias covariates are in describing bias in training presences (Phillips et al. 2009, Warton et al. 2013, Fourcade et al. 2014). As covariates that affect sampling may also affect the distribution of a
species (e.g. avoiding deserts), no method can fully correct for sampling bias in presence-only data without affecting the niche model (Merow et al. 2014, Guillera-Arroita et al. 2015). Correction of sampling bias leads to larger areas of suitable
habitats due to higher suitability estimates in low-accessible sites (e.g. Phillips et al. 2009, Warton et al. 2013; Fig. 5). Predictions at such sites are of lower reliability and should be interpreted with caution (Supplementary material
Appendix 1, Fig. A16 for an example). They can be used to guide future surveys and conservation planning, but not for taking serious conservation decisions (Guisan et al. 2006). Evaluations using spatial-block cross-validation vs. Egyptian
hold-out We used spatial-block cross-validation to avoid overestimating model performance and underestimating predictive errors (Bahn and McGill 2013, Renner et al. 2015, Roberts et al. 2017). Block cross-valuations suggested a better model
performance than evaluation on Egyptian data. This can be explained by differences in sample size and by environmental variability: on average, our cross-validation models had a larger mean number of testing presences and higher environmental
variability compared to evaluations at smaller scale (Table 1). However, evaluations at both scales were positively correlated, which supports the idea that evaluations on cross-validation (larger extent) can be indicative of performance at the
local scale. Evaluation metrics &amp; predictive performance Using AUC and TSS led to consistent conclusions. The overall evaluation scores are fair to high, taking into account that spatially independent evaluation yields lower scores compared to
commonly used random split (Radosavljevic and Anderson 2014). In presence-only SDMs, the use of a particular value for defining good models become unreliable (Yackulic et al. 2013), due to higher uncertainty of estimates at background points and
as the number of background points used is not fixed. In this study, we maintained constant test-data prevalence (1:20) across all comparisons, which gave very similar results, across all species, to the standard default approach of computing AUC
(see Supplementary material Appendix 1, Fig. A14). For some species, the spread over the 100 repetitions was very noticeable, however, making our approach somewhat more robust. The improved predictive performance reported by Syfert et al. (2013),
for example, may be in part attributable to much higher testing prevalence. Also in our study, the larger the number of available presences and the smaller the study area was, the higher were the predictions scores. Comparison of modelling
algorithms The three modelling algorithms applied did not lead to different conclusions and their evaluations were highly correlated. Elastic-net models showed intermediate performance in all situations. GLM (more specifically: the down-weighted
Poisson regression (DWPR) with variable selection) had the highest evaluation on cross-validation, which may suggest that GLM-DWPR is more powerful with a larger number of testing presences. However, GLMs predictions in Egypt were less nuanced
compared to other two modelling algorithms (Supplementary material Appendix 1, Fig. A15a, for example), which explains why it ranked lowest on the Egyptian hold-out. Maxent had the lowest prediction error on the Egyptian data, which suggests its
transferability to situations of low extrapolation. However, Maxent had the lowest evaluation on cross-validation, possibly due to clamping. We applied ‘clamping’ to constrain the response beyond the training range, which changes some of the
predicted values. Clamping can affect model evaluation (the ranking of the predicted values) and, while its effect has not been well-explored in the literature, it seems to depend on the shape of the response curve (at both ends), the importance
of the covariate, and how much environmental extrapolation occurs. We expect the effect of clamping to be small in the Egyptian hold-out compared to the cross-validation, due to less extrapolation. When correcting for bias, no interaction should
be allowed between bias and other covariates so that, for prediction, the bias can be corrected for without affecting the other covariates (Warton et al. 2013). For GLM and elastic net, we have full control of the models’ interactions. However,
the version of Maxent used here (3.3.3k) does not enable users to select which interactions to use, and the use of the product feature inevitably enables all pairwise interactions. In further applications, it may be recommended to disable the
‘product’ feature class while correcting for sampling bias. However, its use here did not lead to different conclusions compared to GLM and elastic net, suggesting that bias-suitability interactions were of limited importance. During the reviewing
of this manuscript, an open-source version of Maxent (maxnet R package: Phillips et al. 2017) was released that uses the glmnet package for L1-regularization. Maxnet provides flexibility for specifying the interactions to be used, so it is
possible to exclude interactions between environmental and bias variables (making them similar to our elastic-net models, but with more flexibility for other feature classes implemented in Maxent, e.g. the hinge). This early version of maxnet
implements an Infinitely-Weighted Logistic Regression (IWLR; Fithian and Hastie 2013) and only L1-regularization (lasso); however, further extensions are possible, e.g. the implementation of DWPR and elastic net (similar to our elastic-net
models). We implemented the down-weighted Poisson regression using both GLM and elastic net. As Poisson models, their predictions have no upper bound and may thus yield extreme predictions. We reported the existence of a few extreme predicted
intensities for many species, which makes it difficult to plot their predictions on a linear scale (see Fig. 5 and Supplementary material Appendix 1, Fig. A15b for an example). In contrast, Maxent puts a constraint on the moments of the
predictions, making them less subject to extreme values (Phillips et al. 2006). Conclusion Data-sparse regions pose challenges to modelling species distributions, exacerbated by noticeable sampling biases. We recommend the use of model-based bias
correction in data-sparse situations, in which other bias corrections methods are not possible; however, the effectiveness of bias correction depends on whether bias covariates are actually able to describe the bias in the available data. Using
covariates to describe site accessibility improved prediction to spatially independent hold-outs, compared to environment-only or effort models. Augmenting local records with data from across the species’ range allowed us to make consistently
high-quality predictions to hold-out data from an entire country (in this case Egypt). Bias-free predictions can enhance future conservation planning and target future surveys when limited resources are available to cover large study areas.
However, due to possible lower certainty at unsurveyed locations, they should be used cautiously (maps including bias are of use only during model cross-validation). Without survey-based presence-absence data, no complete evaluation of the quality
of bias corrections can be attempted. Down-weighted Poisson regression as well as the statistically equivalent Maxent approach led to similar results, with more flexibility in the elastic-net models (e.g. degree of shrinkage, question-led
specification of non-linear effects and interactions). More important than the specific algorithm is to use the point-process modelling framework as such. Acknowledgements We would like to express our sincere thanks for Petr Benda (Charles
University) for comments on the distribution of the bat species. An earlier version of the manuscript was improved by comments of Prof. Francis Gilbert (University of Nottingham). We are also grateful to Belarmain Fandohan, David R. Roberts, and
Simone Ciuti for long discussions and comments on the manuscript. This manuscript benefitted from comments of the subject editor Robert P. Anderson and two anonymous reviewers. A. El-G. is sponsored by the German Academic Exchange Service (DAAD)
through a GERLS scholarship. This work was partially performed on the computational resource ‘bwUniCluster’ funded by the Ministry of Science, Research and Arts and the Universities of the State of Baden-Württemberg, Germany, within the framework
program bwHPC. References Anderson, R. P. 2003. Real vs. artefactual absences in species distributions: Tests for Oryzomys albigularis (Rodentia: Muridae) in Venezuela. – Journal of Biogeography 30: 591–605. Anderson, R. P. and Raza, A. 2010. The
effect of the extent of the study region on GIS models of species geographic distributions and estimates of niche evolution: preliminary tests with montane rodents (genus Nephelomys) in Venezuela. – J Biogeogr 37: 1378–1393. Bahn, V. and McGill,
B. J. 2013. Testing the predictive performance of distribution models. – Oikos 122: 321–331. Barve, N. et al. 2011. The crucial role of the accessible area in ecological niche modeling and species distribution modeling. – Ecol Model 222:
1810–1819. Basuony, M. I. et al. 2010. Mammals of Egypt: atlas, red data listing &amp; conservation. BioMAP &amp; CultNat, EEAA &amp; Bibliotheca Alexandrina, Cairo. 286 pp. Bates, D. et al. 2015. Fitting Linear Mixed-Effects Models Using lme4. – J Stat Softw
67. Boria, R. A. et al. 2014. Spatial filtering to reduce sampling bias can improve the performance of ecological niche models. – Ecol Model 275: 73–77. Chefaoui, R. M. and Lobo, J. M. 2008. Assessing the effects of pseudo-absences on predictive
distribution model performance. – Ecol Model 210: 478–486. Dudík, M. et al. 2005. Correcting sample selection bias in maximum entropy density estimation. Advances in Neural Information Processing Systems 18. The MIT Press, pp. 323-330. URL:
http://papers.nips.cc/paper/2929-correcting-sample-selection-bias-in-maximum-entropy-density-estimation.pdf. Elith, J. et al. 2010. The art of modelling range-shifting species. – Methods Ecol Evol 1: 330–342. Elith, J. et al. 2011. A statistical
explanation of MaxEnt for ecologists. – Divers Distrib 17: 43–57. Elith, J. and Leathwick, J. 2007. Predicting species distributions from museum and herbarium records using multiresponse models fitted with multivariate adaptive regression splines.
– Divers Distrib 13: 265–275. Fithian, W. et al. 2015. Bias correction in species distribution models: pooling survey and collection data for multiple species. – Methods Ecol Evol 6: 424–438. Fithian, W. and Hastie, T. 2013. Finite-sample
equivalence in statistical models for presence-only data. – Ann Appl Stat 7: 1917–1939. Fourcade, Y. et al. 2014. Mapping species distributions with MAXENT using a geographically biased sample of presence data: a performance assessment of methods
for correcting sampling bias. – PloS one 9: e97122. Friedman, J. H. et al. 2010. Regularization paths for generalized linear models via coordinate descent. – Journal of statistical Software 33 - http://www.jstatsoft.org/v33/i01/paper. Gaiji, S. et
al. 2013. Content assessment of the primary biodiversity data published through GBIF network: status, challenges and potentials. – Biodiversity Informatics 8: 94–122. Guillera-Arroita, G. et al. 2015. Is my species distribution model fit for
purpose? Matching data and models to applications. – Global Ecol Biogeogr 24: 276–292. Guisan, A. et al. 2006. Using Niche-Based Models to Improve the Sampling of Rare Species. – Conservation Biology 20: 501–511. Hastie, T. et al. 2009. The
elements of statistical learning: data mining, inference, and prediction - Springer New York. Liu, C. et al. 2013. Selecting thresholds for the prediction of species occurrence with presence-only data. – J Biogeogr 40: 778–789. Lobo, J. M. et al.
2008. AUC: a misleading measure of the performance of predictive distribution models. – Global Ecol Biogeogr 17: 145–151. Mateo, R. G. et al. 2010. Profile or group discriminative techniques? Generating reliable species distribution models using
pseudo-absences and target-group absences from natural history collections. – Divers Distrib 16: 84–94. Merow, C. et al. 2013. A practical guide to MaxEnt for modeling species’ distributions: what it does, and why inputs and settings matter. –
Ecography 36: 1058–1069. Merow, C. et al. 2014. What do we gain from simplicity versus complexity in species distribution models? – Ecography 37: 1267–1281. Muscarella, R. et al. 2014. ENMeval: an R package for conducting spatially independent
evaluations and estimating optimal model complexity for Maxent ecological niche models. – Methods Ecol Evol 5: 1198–1205. Newbold, T. 2010. Applications and limitations of museum data for conservation and ecology, with particular attention to
species distribution models. – Progress in Physical Geography 34: 3–22. Pearce, J. L. and Boyce, M. S. 2006. Modelling distribution and abundance with presence-only data. – J Appl Ecol 43: 405–412. Phillips, S. J. et al. 2006. Maximum entropy
modeling of species geographic distributions. – Ecol Model 190: 231–259. Phillips, S. J. et al. 2009. Sample selection bias and presence-only distribution models: implications for background and pseudo-absence data. – Ecological Applications 19:
181–197. Phillips, S. J. et al. 2017. Opening the black box: an open-source release of Maxent. – Ecography. Phillips, S. J. and Dudík, M. 2008. Modeling of species distributions with Maxent: new extensions and a comprehensive evaluation. –
Ecography 31: 161–175. Ponder, W. F. et al. 2001. Evaluation of Museum Collection Data for Use in Biodiversity Assessment. – Conservation Biology 15: 648–657. Radosavljevic, A. and Anderson, R. P. 2014. Making better Maxent models of species
distributions: complexity, overfitting and evaluation. – J. Biogeogr. 41: 629–643. Renner, I. W. et al. 2015. Point process models for presence-only analysis. – Methods Ecol Evol 6: 366–379. Renner, I. W. and Warton, D. I. 2013. Equivalence of
MAXENT and Poisson point process models for species distribution modeling in ecology. – Biometrics 69: 274–281. Roberts, D. R. et al. 2017. Cross-validation strategies for data with temporal, spatial, hierarchical, or phylogenetic structure. –
Ecography 28. Smith, A. B. 2013. On evaluating species distribution models with random background sites in place of absences when test presences disproportionately sample suitable habitat. – Diversity Distrib. 19: 867–872. Stolar, J. and Nielsen,
S. E. 2015. Accounting for spatially biased sampling effort in presence-only species distribution modelling. – Divers Distrib 21: 595–608. Syfert, M. M. et al. 2013. The effects of sampling bias and model complexity on the predictive performance
of MaxEnt species distribution models. – PloS one 8: e55158. Warren, D. L. et al. 2014. Incorporating model complexity and spatial sampling bias into ecological niche models of climate change risks faced by 90 California vertebrate species of
concern. – Divers Distrib 20: 334–343. Warton, D. and Aarts, G. 2013. Advancing our thinking in presence-only and used-available analysis. – The Journal of Animal Ecology 82: 1125–1134. Warton, D. I. et al. 2013. Model-based control of observer
bias for the analysis of presence-only data in ecology. – PloS one 8: e79168. Yackulic, C. B. et al. 2013. Presence-only modelling using MAXENT: when can we trust the inferences? – Methods Ecol Evol 4: 236–243. Table 1: List of Egyptian bat
species used in this study, with total number of records available, number of unique records (in parentheses: the number of records used to train the model on cross-validation/those kept aside for independent evaluation, i.e. ‘Egyptian records’),
number of occupied grid cells at the resolution of 5 × 5 km (number of cells outside/inside Egypt), and best estimated number of background points used to run the DWPR-GLM and elastic-net models. See main text and Supplementary material Appendix
1, Fig. A5 for more details. Species # Records (Total) # Records (unique) # occupied cells # background points (×1000) Asellia tridens (Trident Leaf-nosed Bat) Barbastella leucomelas (Sinai Barbastelle) Eptesicus bottae (Botta’s Serotine Bat)
Hypsugo ariel (Fairy Pipistrelle) Nycteris thebaica (Egyptian Slit-faced Bat) Nycticeinops schlieffeni (Schlieffen&#39;s Bat) Otonycteris hemprichii (Hemprich’s Long-eared Bat) Pipistrellus deserti (Desert Pipistrelle) Pipistrellus kuhlii (Kuhl&#39;s
Pipistrelle) Pipistrellus rueppellii (Rueppell’s Pipistrelle) Plecotus christii (Desert Long-eared Bat) Rhinolophus clivosus (Arabian Horseshoe Bat) Rhinolophus hipposideros (Lesser Horseshoe Bat) Rhinolophus mehelyi (Mehely’s Horseshoe Bat)
Rhinopoma cystops (Lesser Mouse-tailed Bat) Rhinopoma microphyllum (Greater Mouse-tailed Bat) Rousettus aegyptiacus (Egyptian Fruit Bat) Tadarida aegyptiaca (Egyptian Free-tailed Bat) Tadarida teniotis (European Free-tailed Bat) Taphozous
nudiventris (Naked-Bellied Tomb Bat) Taphozous perforatus (Tomb Bat) Figure 1: Flowchart of analyses in this study, illustrated with data for Asellia tridens. Sampling-bias models and modelling algorithms were combined factorially. Only results
for validation with AUC are presented in the manuscript, while TSS-results are given in the appendix. Figure 2: Mean AUC of each species calculated either on 5-fold spatial block cross-validation (a) or in Egypt (b). Each plot compares evaluation
of environment-only models to bias-accounting models (effort and accessibility), without correcting for sampling bias (Modelling evaluation; see Appendix 5.1). Each species is represented by different symbols (see Supplementary material Appendix
1, Fig. A7 for species names). Red lines indicate overall mean AUC for each modelling algorithm and bias manipulation applied. For evaluations of bias-free prediction, see Fig. 3. Figure 3: Species mean AUC calculated either on cross-validation
(a) or in Egypt (b), after sampling bias correction (using bias-free prediction; for details, see Supplementary material Appendix 6.2). Each species is represented by different symbols (see Supplementary material Appendix 1, Fig. A7 for species
names). Red lines indicate the overall mean AUC at each modelling algorithm and bias models applied. Figure 4: Kendall’s correlation of the per-species mean AUC between pairs of modelling algorithms. Each species is represented by different
symbols (see Supplementary material Appendix 1, Fig. A7 for species names) with colours referring to bias models (using predictions of environment-only model and bias-free prediction of accessibility and effort model). ‘M’ indicates the overall
mean evaluation. Top row panels are mean evaluation using spatial block cross-validation, while those in the bottom row are independent evaluations in Egypt. Figure 5: Mean cross-validated predicted distribution of Otonycteris hemprichii, of
different modelling algorithms (rows) and bias models (columns). Maps were rescaled to relative intensities between zero and one, as different modelling algorithms do not have the same scale. Darker colour indicates higher predicted relative
intensity. Blue points (in the top left panel) represents available records used for cross-evaluation model training. For visualisation, extreme values (&gt; 0.9995 quantile of predicted values) were replaced with their next smaller value, as GLM and
elastic net are subject to some few extreme predictions (see main text, and Supplementary material Appendix 1, Fig A15B for a comparison with unlimited predictions). For predicted maps in Egypt see Supplementary material Appendix 1, Fig. A15A.
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Wrong, but useful: regional species distribution models may not be improved by range-wide data under biased sampling</title>
      <link>/publication/2018_elgabbas_dormann_ecologyevolution/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>/publication/2018_elgabbas_dormann_ecologyevolution/</guid>
      <description>&lt;div style=&#34;display: none&#34;&gt;
Wrong, but useful: regional species distribution models may not be improved by range-wide data under biased sampling&lt;br&gt;
Ahmed El-Gabbas&lt;br&gt;
Carsten F. Dormann&lt;br&gt;
https://doi.org/10.1002/ece3.3834&lt;br&gt;
10.1002/ece3.3834&lt;br&gt;
Species distribution modeling (SDM) is an essential method in ecology and conservation. SDMs are often calibrated within one country&#39;s borders, typically along a limited environmental gradient with biased and incomplete data, making the quality of
these models questionable. In this study, we evaluated how adequate are national presence-only data for calibrating regional SDMs. We trained SDMs for Egyptian bat species at two different scales: only within Egypt and at a species-specific global
extent. We used two modeling algorithms: Maxent and elastic net, both under the point-process modeling framework. For each modeling algorithm, we measured the congruence of the predictions of global and regional models for Egypt, assuming that the
lower the congruence, the lower the appropriateness of the Egyptian dataset to describe the species&#39; niche. We inspected the effect of incorporating predictions from global models as additional predictor (“prior”) to regional models, and
quantified the improvement in terms of AUC and the congruence between regional models run with and without priors. Moreover, we analyzed predictive performance improvements after correction for sampling bias at both scales. On average, predictions
from global and regional models in Egypt only weakly concur. Collectively, the use of priors did not lead to much improvement: similar AUC and high congruence between regional models calibrated with and without priors. Correction for sampling bias
led to higher model performance, whatever prior used, making the use of priors less pronounced. Under biased and incomplete sampling, the use of global bats data did not improve regional model performance. Without enough bias-free regional data,
we cannot objectively identify the actual improvement of regional models after incorporating information from the global niche. However, we still believe in great potential for global model predictions to guide future surveys and improve regional
sampling in data-poor regions.&lt;br&gt;
Species distribution models (SDMs) are statistical methods that relate species information (either presence-only or presence–absence) to environmental variables to infer spatially explicit habitat suitability. They are being used intensively as a
standard tool for estimating potential range shifts under climate change, assessing invasion risk, locate future survey sites, and conservation planning and prioritization (Araújo, Alagador, Cabeza, Nogués-Bravo, &amp; Thuiller, 2011; Guisan &amp;
Zimmermann, 2000; Guisan et al., 2013; Rodríguez, Brotons, Bustamante, &amp; Seoane, 2007; Thuiller et al., 2005). Although these methods have limitations and uncertainties (Araújo &amp; Guisan, 2006; Dormann, Purschke, Márquez, Lautenbach, &amp; Schröder,
2008; Guisan &amp; Thuiller, 2005), they constitute the best available tools when not much detailed information on the ecology and physiology of the species is available (Warren, Wright, Seifert, Shaffer, &amp; Franklin, 2014).&lt;br&gt;
In developing countries, the majority of species sightings are scattered, opportunistic, and recorded mainly in museum catalogues, personal collections, and the literature. Due to political instability and limited funds dedicated to wildlife
conservation (amongst other reasons), there is no systematic nation-wide sampling scheme for collecting biological information in most developing countries. Many of these countries do not share their biodiversity data, making them highly
under-represented at international data depositories, such as the Global Biodiversity Information Facility (GBIF), with many more records from countries with high GDP (Newbold, 2010). Furthermore, data from developing countries are particularly
(but not exclusively) spatially biased (more records from accessible locations near roads and cities) and taxonomically biased (toward larger or charismatic species). Spatial bias poses a problem for SDMs, which, in their default approach, assume
that available presence locations represent a random (representative) sample in the environmental/geographical space, with no spatial dependencies (Elith et al., 2011; Renner et al., 2015). This assumption is hardly ever met due to sampling bias,
imperfect detectability and spatial auto-correlation (Guillera-Arroita et al., 2015). When high sampling bias exists, SDM predictions provide an estimate not necessarily of the species suitability, but more of the patterns of the sampling effort
and detectability (Elith et al., 2011; Yackulic et al., 2013). Several methods have been proposed to correct for sampling bias (e.g., target-group background: Phillips et al., 2009; spatial filtering: Anderson &amp; Raza, 2010; sampling bias
predictors: Warton, Renner, &amp; Ramp, 2013); however, no method seems to be able to fully correct for sampling bias in presence-only data (El-Gabbas &amp; Dormann, 2017; Merow et al., 2014).&lt;br&gt;
One of the major challenges of SDM studies is how to determine the extent of the study area appropriately. Study area should be objectively determined to cover accessible areas by the species within its known complete range, allowing for wider
range of environmental variation and extremes occupied by the species (Barve et al., 2011; Raes, 2012; Sánchez-Fernández, Lobo, &amp; Hernández-Manrique, 2011). However, it is common that study areas are unjustifiably determined based on geographical
or political borders for regional/local conservation actions, resulting in models calibrated with a limited range of environmental conditions that do not capture much of the species&#39; niche and hence is insufficient to describe its environmental
tolerance (Raes, 2012; Titeux et al., 2017). This leads to the truncation of the estimated response curves, underrepresentation of areas of suitable habitats, and limiting the predictive power of the models (Sánchez-Fernández et al., 2011;
Thuiller, Brotons, Araújo, &amp; Lavorel, 2004). This is more problematic when the aim of the study is to extrapolate beyond the training range, either in time or space (Barbet-Massin, Thuiller, &amp; Jiguet, 2010; Thuiller et al., 2004), or in situations
where available data are few, opportunistic, or with high (typically unknown) sampling bias. The paucity of available records in developing countries, coupled with clear signs of sampling bias and limited local environmental gradients, makes it
challenging to establish robust SDMs for a variety of taxonomic groups at the national scale.&lt;br&gt;
In this article, we evaluate the adequacy of regional presence-only data (in this case from within a developing country&#39;s political borders) for constructing SDMs. More specifically, we compare bat occurrence predictions from regional and global
SDMs for the country of Egypt, in many respects exemplary for developing countries. Egypt shows much lower environmental variability compared to the global extents of the species (see Figures 1 and S1) and comprises only a small proportion of
available global records. This makes the quality of regional SDMs, that is, those built only on the sparse Egyptian data, questionable. Global models (at species-specific global range) should in this case be more reliable than regional models (in
Egypt) in describing the climatic niche of species because they are calibrated with a much higher number of presences and capture a much wider range of occupied (or, more generally, accessible) environmental conditions (Pearson, Dawson, &amp; Liu,
2004). Thus, we evaluate predictions from regional and global SDMs for Egypt, arguing that the less similar they are, the more the local data describe sampling effort rather than the ecology of bats. Furthermore, we investigate how much correction
for sampling bias (using bias predictors, in both regional and global SDMs) helps to improve the local predictions for Egypt.&lt;br&gt;
Predictions from global models interpolated to Egypt represent a spatial-explicit information on the species potential distribution that is independent from regional data available from Egypt, and thus can be useful to improve predictions of
regional models when used as additional predictors (cf. “informative offset”: Merow, Allen, Aiello-Lammens, &amp; Silander, 2016). We explore how much global predictions (interpolated to Egypt) improve Egyptian regional models when used as predictor
“prior” to describe the environmental niche (again, with and without correcting for sampling bias).&lt;br&gt;
Study design and species&lt;br&gt;
This study builds on a comparison of methods to correct for sampling biases (El-Gabbas &amp; Dormann, 2017), adding an evaluation of regional species distribution models based on national records. We collected records for Egyptian bat species (from
within Egypt and their global extents) from different sources (Appendix S1 and El-Gabbas &amp; Dormann, 2017). Four species with fewer than eight unique sightings in Egypt were excluded from the analyses, yielding a total of 17 species (Table S1). For
the selected species, we created regional models using presence locations and environmental data only for Egypt (“regional SDMs”). “Regional” refers here to a geographic extent much smaller than the range of the species, but of much coarser grain
than a local dataset. We also created analogous models across the global range (“global SDMs”): These models were made for each species-specific global extent (a buffered bounding box around all global records), excluding Egyptian records to
maintain independence (and to allow for valid comparisons) between the predictions of the regional and global models (see below; and El-Gabbas &amp; Dormann, 2017 for details). Both scales are nested in geographical and environmental space: Our
regional models are calibrated within a subset of each species-specific global extent. At either scale, we used two modeling algorithms under the point-process modeling framework (Maxent and elastic net; Renner et al., 2015), with two options on
dealing with sampling bias (with and without bias correction), and evaluated the results using spatial-block cross-validation (Roberts et al., 2017).&lt;br&gt;
Environmental variables&lt;br&gt;
Potential environmental predictors (at the total study area covering both scales) and species records were projected into Mollweide equal-area projection at a resolution of 5 × 5 km2. Using the same pixel size and projection maintains consistency
of the analyses between regional and global models (Budic, Didenko, &amp; Dormann, 2016). As the correlation between predictors varies from one study area to another, different environmental predictor combinations were used at regional and global
scales. Some predictors were not useful at the regional scale, and hence were excluded a priori; for example, precipitation of driest month does not show any variability across Egypt because most of Egypt receives no precipitation at all in
summer, reflecting its hyper-arid climate (El-Gabbas, Baha El Din, Zalat, &amp; Gilbert, 2016). We ensured minimum multi-collinearity at both scales by selecting only predictors that maintain a maximum generalized variance inflation factor value less
than 3 (see Table S2 for the list of predictors used at either scale).&lt;br&gt;
Modeling algorithms&lt;br&gt;
We used two modeling algorithms: Maxent and elastic net. Maxent (Phillips &amp; Dudík, 2008; v3.3.3k) is a machine-learning presence-background SDM algorithm. It outperforms other presence-only SDM algorithms, especially at smaller sample sizes (e.g.,
Wisz et al., 2008), due to its use of (some form of) lasso regularization. Elastic net (Friedman, Hastie, &amp; Tibshiani, 2010) is an extension of GLMs that uses “lasso” and “ridge” regularization rather than AIC to select the most suitable model,
and hence is similarly resistant to overfitting. We applied both algorithms under the point-process modeling framework following recommendations of Renner et al. (2015), changing some of Maxent&#39;s default settings (e.g., to “noautofeature,”
“noaddsamplestobackground,” and “noremoveduplicates”), and used the implementation of “down-weighted Poisson regression” for elastic-net models. For each calibrated model of either algorithm, we adjusted against unnecessary complexity (Merow et
al., 2014) using five-fold spatial-block cross-validation, estimating the best combination of Maxent&#39;s feature classes and regularization multiplier based on maximizing the mean testing AUC (Muscarella et al., 2014), and the optimum α (which
describes the balance between ridge and lasso) for elastic net.&lt;br&gt;
Adjusting for sampling bias&lt;br&gt;
In addition to “environment-only” models (without bias correction), we use two different methods of predicting from models that incorporate bias: “bias-predictor” and “bias-corrected.” In both methods, we use sampling bias predictors as our
estimate of bias: three layers describing distances to main roads, cities, and protected areas (Warton et al., 2013). Bias-predictor models use the bias layers simply as an extra set of predictors, and during prediction also their values change.
Bias-corrected models try to factor out the bias by setting the bias variables to zero (see Warton et al., 2013). The three options for sampling bias (none, predictor, and correction) were applied to regional and global models, with bias
predictors nested for regional scale within the global scale.&lt;br&gt;
Model evaluation and the use of spatial priors&lt;br&gt;
We evaluated regional model performance using AUC as a threshold-independent metric. Despite the criticism of the use of AUC to evaluate the performance of presence-only SDMs (e.g., Lobo, Jiménez-Valverde, &amp; Real, 2008), our use of AUC for
comparisons between models of the same species, predictors, and study area is valid (Anderson &amp; Gonzalez, 2011; Wisz et al., 2008). We did not use AUC to quantify model performance (goodness of fit), but rather as a measure of the relative ranking
of predictions at testing presence and background locations. We calculated AUC on five-fold spatial-block cross-validation to maintain spatial independence between training and testing data (Fithian, Elith, Hastie, Keith, &amp; O&#39;Hara, 2015; Roberts
et al., 2017): The same blocking structure (how spatial blocks are distributed into cross-validation folds) is used for each species, with balanced prevalence among blocks and same block sizes, allowing for valid AUC comparisons for the same
species. The mean value of testing AUC on cross-validation is reported.&lt;br&gt;
To quantify the efficacy of Egyptian data to construct SDMs, we calculated the geographical congruence (Schoener&#39;s D; Schoener, 1968; Warren, Glor, &amp; Turelli, 2010) between continuous predictions of the global and regional SDMs for Egypt (scaled
to sum to one; without and with bias correction). Our assumption is that the higher the geographical congruence, the more suitable the Egyptian records are to parameterize regional models. When assessing the congruence between maps we used all
three bias options, while for regional comparisons based on AUC we only used the first two models (environment-only and bias-predictor), due to the lack of bias-free testing-data from Egypt required to evaluate bias-corrected predictions.
Geographical congruence and AUC gave similar results, indicating that geographical congruence indeed measured how similarly well, not how similarly poorly models predicted.&lt;br&gt;
We then measured the improvement of regional SDMs after incorporating a spatial-explicit information on the global climatic niche. More specifically, for each species we used predictions from the global SDM interpolated to Egypt (i.e., not using
the Egyptian data, and thus referred to hereafter as “prior”) as an additional predictor to create a new set of regional models. We had three types of priors representing the predictions of global models for Egypt: 1) from the environment-only
model, “Priorenv-only”; 2) a prediction incorporating the bias layer as a predictor to adjust for sampling bias, “Priorbias-predicted”; and 3) a prediction from a model that has factored out bias, “Priorbias-corrected”. Modeling algorithms were
not mixed, that is, global models from Maxent were used only for regional models with Maxent, and analogously for elastic-net models. We quantified the improvement due to priors in two ways. First, we measured changes in model performance (AUC).
Secondly, we calculated the map congruence between regional models&#39; predictions in Egypt with and without incorporating priors: the higher the map congruence, the lower the contribution of the prior to the regional SDM. One-tailed paired t-test
(df = 16) was used for comparisons between each pair of modeling algorithms, sampling bias options, and changes in AUC and map congruence.&lt;br&gt;
The relative importance of environmental variables (permutation importance calculated by Maxent) varied at global and regional scales. When incorporated, the accessibility bias predictors at both scales had high Maxent permutation importance
(particularly, “distance to cities” was of significantly higher importance than all but one variable [p .05; nonsignificant only for Bio4 at global scale and Bio6 at regional scale], and “distance to roads” which had a significantly higher average
importance than three different environmental variables at either scales; Figure 2). Furthermore, the response of species to environmental predictors was, unsurprisingly, different at both scales. For example, for Eptesicus bottae at the global
scale, the response to precipitation of the coldest quarter increased sharply at low precipitation values (approx. 0–130 mm), then remained high or decayed depending on whether the global bias predictors were used or not, respectively (Figure
S2a). At the regional scale, however, the species response was highest at extremely low precipitation values (around 10 mm), then declined sharply (Figure S2c).&lt;br&gt;
Global versus regional SDMs&lt;br&gt;
Different areas were identified as suitable in models either using data from the full range or just from Egypt, with low geographic congruence between the predictions of global and regional models for Egypt (Figure 3). The incorporation of bias
predictors (at both scales) did not lead to substantial congruence improvement (yet statistically significant; all p .01). The congruence was highest when bias-corrected models were used (statistically higher than environment-only and
bias-predicted models for Maxent and elastic net, p .001). Maxent and elastic net yielded similar values for congruence, with an advantage of Maxent for bias-predictor models (p .05).&lt;br&gt;
The use of prior information from the entire range&lt;br&gt;
The use of priors did not lead to AUC improvement, except when using Priorbias-predictor (p .05; Figure 4a). Results were similar for both Maxent and elastic net, with higher AUC values for Maxent (all p .01). Maxent showed relatively low
permutation importance of the different prior variables, except for Priorbias-predictor which had high contributions to the models (all p .0001, although also with high variability; Figure S3, left panel).&lt;br&gt;
The incorporation of prior variables as predictors yielded high geographical congruence between the predictions of regional models without and with priors (Figure 5). However, the congruence values depended on the prior used. The use of
Priorenv-only or Priorbias-corrected led to high congruence, indicating little additional information provided by the priors. In contrast, when Priorbias-predictor was used, geographical congruence was less pronounced (p .001), suggesting that
here information different from the regional data entered the model. Both Maxent and elastic net produced similar values for congruence, with slightly higher values for elastic net when Priorbias-predictor was used (marginally significant; p =
.042).&lt;br&gt;
Correction of regional sampling bias&lt;br&gt;
When regional bias predictors were incorporated into the SDMs, the regional models performed better (higher AUC; all p .05), leading to a negligible effect of priors (Figure 4b). Maxent has relatively higher AUC scores than elastic net (all p
.01). However, Priorbias-predictor showed equivalently high AUC values whether or not regional bias predictors were included (p &gt; .7; see Figure 4a,b for a comparison). This was also evident by the much lower permutation importance of prior
predictors when regional bias predictors were incorporated, with relatively higher importance for Priorbias-predictor (all p .05; Figure S3, right panel).&lt;br&gt;
Incorporating regional bias predictors led to similar patterns of congruence (between predictions of regional SDMs created with or without priors) to those which did not incorporate bias (Figure 5 vs. Figure S4, light gray boxes), with relatively
lower congruence when Priorbias-predictor was used. However, bias-correction (factoring out the bias) did not affect congruence for Maxent, while much lower congruence values were observed for elastic net whichever priors were used (Figure S4,
dark gray boxes). In other words, regional bias correction led to less agreement between regional model predictions (with and without priors) for elastic net, regardless of which prior variables were used.&lt;br&gt;
In this study, we evaluated how much improvement to the regional SDMs for Egypt occurs by incorporating additional information (the “priors”) representing the global climatic niche from outside Egypt. First, without providing information on
regional bias (no regional bias correction), Priorenv-only and Priorbias-corrected did not lead to improvements in the regional models: Similar AUC values (Figure 4a) and high geographical congruence (Figure 5) imply that they do not provide new
information to the regional models. However, the use of Priorbias-predictor led on average to higher AUC and lower geographical congruence, signaling that new information was provided to the models. This was supported in Maxent models by the
higher permutation importance of Priorbias-predictor, compared to the other two options of priors (Figure S3, left panel). On the other hand, when regional bias predictors were incorporated, all models had improved AUC, whether or not priors were
used (Figure 4b). Regional bias predictors describe the local bias existing in the Egyptian dataset, and their use led to higher AUC, in accordance with other studies (El-Gabbas &amp; Dormann, 2017; Warton et al., 2013). The use of regional bias
predictors makes the contribution of priors negligible: Priorenv-only and Priorbias-corrected had an extremely low contribution to these models, only slightly higher for Priorbias-predictor (Figure S3, right panel). Generally, Maxent and elastic
net led to very similar results, with slightly higher discrimination ability for Maxent.&lt;br&gt;
Priorbias-predictor implicitly contains information on the regional bias of the records in Egypt, because it represents predictions of equivalent global models calibrated with accessibility bias variables (regional bias variables represent a
narrower range than their equivalent variables at global scale). In contrast to bias-free predictions, the use of bias variables as predictors gives higher predicted suitabilities at locations of high accessibility (e.g., closer to roads and
cities), which is the reason for high AUC scores when evaluation datasets are similarly biased (Warton et al., 2013). The available dataset for Egyptian bats is spatially-biased, with more records collected near roads and cities (El-Gabbas &amp;
Dormann, 2017), and hence Priorbias-predictor describes the available data better than the other two priors. The relatively modest contribution of Priorbias-predictor, and even lower contribution of the other two priors, can be understood as the
result of the unavailability of complete, bias-free data from Egypt (see below). Furthermore, Priorenv-only and Priorbias-corrected are highly correlated with some other environmental variables in Egypt (higher than for Priorbias-predictor),
particularly for Bio19 (precipitation of coldest quarter) and Bio9 (mean temperature of driest quarter; Figure S5), and hence to a large extent provide redundant information.&lt;br&gt;
The three prior suitabilities show low geographical congruence with their corresponding regional predictions in Egypt (Figures 3 and S6, e.g., maps), meaning they (global models) identify different sites as suitable than do models based on
Egyptian records. This can be explained by factors related to model misspecification (e.g., the variables used and violation of model assumptions), the difficulty of modeling widespread species with high accuracy (Stockwell &amp; Peterson, 2002), the
low quality of available data, or species-specific reasons (e.g., species plasticity and the existence of ecotypes; Randin et al., 2006). We exclude environmental extrapolation as a reason for the on average low performance of the predictions of
the global model for Egypt, as we included environmental data for the area of Egypt in these models (but not the records), and hence, the predictions are not outside the realm of the global model (and hence do not represent an extrapolation).&lt;br&gt;
While it is advisable to check for collinearity at training and prediction scales (Elith, Kearney, &amp; Phillips, 2010), it is not always easy to maintain a representative set of variables that are uncorrelated at both scales. Although we minimized
the correlation between environmental variables at global and regional scales to avoid unnecessarily high variance in model parameters, the correlation among environmental variables is, inevitably, not constant over space (Dormann et al., 2013).
Some of the variables used at the global scale have high correlation in Egypt, making the reliability of predictions in Egypt less stable (Dormann et al., 2013; Elith et al., 2010). Furthermore, the quality of environmental variables is not
constant in space. For example, the WorldClim data (Hijmans, Cameron, Parra, Jones, &amp; Jarvis, 2005; the source of most of the environmental variables used in this study) were adroitly prepared using interpolation of data from global weather
stations. Weather stations are not evenly distributed in space: Climate data for areas such as Arabia and the Sahara (including Egypt) are interpolated using very few weather stations with high spatial clustering (see figure 1 in Hijmans et al.,
2005), and hence, the interpolations are of potentially higher uncertainty that can affect the quality of calibrated models (Phillips, Anderson, &amp; Schapire, 2006). This problem is not exclusive to the WorldClim data, but holds for any
environmental layers derived from spatially-biased weather stations.&lt;br&gt;
The environmental variables used may have been insufficient to characterize the species niche (Phillips et al., 2006). It is recommended to use proximal predictors (e.g., food sources or suitable roosting sites for bats) that directly describe the
required resources and physiological limits than more indirect distal predictors (e.g., altitude; Austin, 2007; Merow et al., 2014). The use of proximal variables increases the transferability of models in space (Elith &amp; Leathwick, 2009; Franklin,
2009). However, determining a set of species-specific proximal predictors is not possible without detailed knowledge of the ecology and physiology of each species, either unknown for most species (especially for bats) or not yet available at large
scales (e.g., abundance of prey; Merow et al., 2014; Herkt, Matthias, Barnikel, Skidmore, &amp; Fahr, 2016; Petitpierre, Broennimann, Kueffer, Daehler, &amp; Guisan, 2017). The majority of SDM studies use (the easier to obtain) distal variables as
surrogates for proximal variables; however, even if distal variables can indirectly describe the species requirements, the correlation between proximal and distal variables is not constant in space (Dormann et al., 2013; Elith &amp; Leathwick, 2009;
Merow et al., 2014). Examples of missed variables which can potentially improve model transferability for bats include locations of suitable roosting and foraging sites, proximity to water, food sources (Herkt et al., 2016; Razgour, Rebelo, Di
Febbraro, &amp; Russo, 2016). Regional models were calibrated for a limited environmental range (Figure S1), potentially contributing to the disagreement between regional and global model predictions.&lt;br&gt;
While excessive model complexity can lead to overfitting to training data and consequent limited model transferability in space and time, we reject overfitting as a reason for the limited usefulness of priors. We limited overfitting using
regularized modeling approaches, calibrated by spatial cross-validation blocks in a way that balances the number of presence locations and environmental variability between cross-validation folds (avoiding extrapolation) and adequately constrains
the complexity of (both regional and global) models. That said, it is not clear how much model complexity optimization is affected by the limited number and quality of records (including sampling bias).&lt;br&gt;
Predictions from global models interpolated to Egypt may well still describe the potential distribution of bats in Egypt. Their limited usefulness in our study only shows that the global dimension did not add new information, given the limitations
of the available data from Egypt. If unbiased occurrence data were available, global models may indeed predict well in Egypt. Moreover, available bat records in Egypt are few and spatially-biased toward easily accessible areas, with the majority
collected from relatively old literature and museum specimens. Most are opportunistic data gathered with an unknown sampling strategy (see Appendix S1). Due to their nocturnal and elusive behaviour, high maneuverability, and the need for
specialized bat detectors for effective recording, it is challenging to obtain high-quality records for bats in developing countries (Razgour et al., 2016). Information on their geographical distribution is very limited, making bats highly
under-represented in SDM studies (Herkt et al., 2016; Razgour et al., 2016), and Egypt is no exception. Finally, sampling bias can strongly affect model quality (Phillips et al., 2009), and while we attempted to correct for sampling bias in our
models, we cannot quantify the efficiency of bias correction without bias-free data for comparison (Phillips et al., 2009; Warton et al., 2013), unavailable in most presence-only studies, especially in developing countries. The results of this
study call for improved, systematic sampling of species occurrences in regions where currently only biased and scarce data are available.&lt;br&gt;
We have shown that the use of global bat data did not improve regional model performance for Egypt. We relate this to the difficulty of calibrating SDMs of widespread species at extremely large study areas that cover many biogeographical regions
and to data quality issues (mainly the quantity of available data dominated by high sampling bias). Due to the lack of high-quality data and limited environmental gradients in Egypt, regional SDMs seem to be insufficient to determine new survey
sites (a point also made by Sánchez-Fernández et al., 2011). Improving the sampling of fauna and flora species from data-poor countries (such as Egypt, particularly from the less visited areas) would enhance regional SDMs in these countries and
consolidate the usefulness of these models to discover new populations.&lt;br&gt;
Although our results showed that predictions from global SDMs failed to improve regional predictions calibrated with low-quality and spatially-biased data, we still believe in great potential for SDMs that integrates global and regional data to
improve future local sampling in data-poor countries like Egypt. Patterns of potential distribution (of global models interpolated to Egypt) can guide future surveys and help to discover new populations. In our analyses, we excluded Egyptian data
for creating the global models to maintain consistency of comparisons between predictions of regional and global models. However, this is not necessary for real applications, and it would seem preferable to include regional data in a comprehensive
model that covers the biogeographical region to improve model predictability. For example, to improve sampling of under-reported bat species in Egypt, we think that a larger-scale model should be created, with the study area determined objectively
based on the available data from Egypt and adjacent arid areas (e.g., Arabia and the Sahara) in order to meet the stationarity assumption (constant species–environment relationships with no change in niche characteristics; Anderson &amp; Gonzalez,
2011; Dormann et al., 2012) and then crop the prediction maps to Egypt. This is of mutual benefit not only for Egypt, but also for targetting efforts in the adjacent areas as well, which can help to improve the conservation status of some species.
However, obtaining enough data from adjacent areas will remain challenging for many species.&lt;br&gt;
ACKNOWLEDGMENTS We would like to express our sincere thanks to Petr Benda for comments on the global distribution of the bat species. An earlier version of the manuscript was improved by comments of Francis Gilbert and David R. Roberts. AE-G is
sponsored by the German Academic Exchange Service (DAAD) through a GERLS scholarship. This work was partially performed on the computational resource “bwUniCluster” funded by the Ministry of Science, Research and Arts and the Universities of the
State of Baden-Württemberg, Germany, within the framework program bwHPC. The article processing charge was funded by the German Research Foundation (DFG) and the University of Freiburg in the funding programme Open Access Publishing.&lt;br&gt;
AUTHOR CONTRIBUTIONS AE-G and CFD contributed to idea and design of study, and comments and revisions; AE-G contributed to data curation and statistical analysis, and first drafted the writing. Both authors contributed critically to the drafts and
gave final approval for publication.&lt;br&gt;
CONFLICT OF INTEREST None declared.&lt;br&gt;
Figure 1 The distribution of Asellia tridens at spatial (a) and environmental (b) space. The map a shows the species-specific global extent of this species, with dots representing the spatial distribution at global (blue) and regional (black)
scales. Panel b shows a scatterplot of the first two PCA axes of all available environmental covariates within the entire study area. The first two axes account for 94.2% of the environmental variation. Blue and black dots are presence locations
of the species outside and inside Egypt, respectively; light gray points are pixels without any sightings at global scale; dark gray points represent the available environmental space in Egypt. Figure S1 shows equivalent plot for all study species
together&lt;br&gt;
Figure 2 Mean permutation importance of environmental variables used at global (left) and regional (right) models (from Maxent). Dots and error bars represent the overall mean and standard deviation of the average permutation importance of the
seventeen study species, respectively. Blue dots/bars represent environment-only models; red dots/bars represent comparable models with accessibility bias variables incorporated as predictors. When included, bias predictors have a high
contribution (particularly distance to main cities at both scales, and distance to roads in Egypt), compared to many environmental variables. For more details on the environmental variables used, see Table S2&lt;br&gt;
Figure 3 Boxplots for the geographical congruence (Schoener&#39;s D) between mean predictions of global and regional models for Egypt (with no priors). Schoener&#39;s D ranges from zero to one, representing situations of no to full congruence,
respectively. “Env-only” are models calibrated only with environmental variables. “Bias-predictor” models add accessibility bias variables as predictors to the model. “Bias-corrected” models also use bias variables to set bias to zero during
prediction (i.e., bias factored-out)&lt;br&gt;
Figure 4 Boxplots for the mean AUC values (on cross-validation) calculated for different options of modeling algorithms, bias manipulations, and priors. (a) A comparison between mean AUC values of no-prior regional models and equivalent models
that use different options of priors (without regional bias incorporated as predictors). (b) Same as a, with regional bias variables included as predictors&lt;br&gt;
Figure 5 Geographical congruence between the predictions of regional SDMs calibrated without priors and the three versions of regional models that used a prior variable. Bias variables were not incorporated as predictors in the regional SDMs.
There were three options of prior options: “Env-only” are predictions of global SDMs without incorporating sampling bias; “Bias-predictor” priors incorporate global accessibility bias variables as predictors in the model; and “Bias-corrected”
priors incorporate bias-corrected (set to zero) predictions from global models for Egypt&lt;br&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
